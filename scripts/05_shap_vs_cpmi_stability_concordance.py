# Auto-generated from XOCTANE.ipynb (extracted).
# Patched for GitHub reproducibility: uses env vars instead of local absolute paths.
import os
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
ROOT = Path(os.environ.get('XOCTANE_ROOT', str(REPO_ROOT))).resolve()
DATA_DIR_ENV = os.environ.get('XOCTANE_DATA_DIR', '')
if not DATA_DIR_ENV:
    raise SystemExit('Please set XOCTANE_DATA_DIR to the dataset root directory (see README).')
DATA_DIR = Path(DATA_DIR_ENV).resolve()

# Default output directories (created if missing)
RES_DIR = ROOT / 'Results'; RES_DIR.mkdir(parents=True, exist_ok=True)
FIG_DIR = ROOT / 'figures'; FIG_DIR.mkdir(parents=True, exist_ok=True)

# === SHAP vs CP-MI (PER PLATFORM) — stability + concordance plots ============================
# This is a PER-PLATFORM revision of your original "BestCases" script.
#
# What changes:
#   - Uses per-platform winners from:
#       Results/BEST_in_DesignSpace_Post_per_platform_details.csv
#   - Uses SHAP tables generated by your per-platform SHAP run:
#       Results/Explainability_SHAP_BestPlatforms/SHAP_BESTPLAT_full_<setup>_<anomaly>_WIN..._KF..._PCT..._M<method>.csv
#   - For each PLATFORM (DDR4, DDR5) and each SUBSPACE (compute/memory/sensors), it:
#       1) Loads CP-MI ranks (from FeatureRankOUT) for that platform's chosen WIN/K
#       2) Aggregates SHAP across the platform's anomalies (equal-weight mean, missing=0)
#       3) Computes Spearman (rank/percentile/score) and top-% Jaccard/overlap
#       4) Produces platform-level plots (scatter + jaccard curve + overlap bars)
#
# Outputs:
#   Results/Explainability_SHAP_BestPlatforms/
#     - SHAP_vs_CPMI_summary_PLATFORM.csv
#     - comparison_plots_platform/
#         DDR4_compute_scatter_cpmi_vs_shap.png
#         DDR4_compute_scatter_percentile_ranks.png
#         DDR4_compute_jaccard_vs_pct.png
#         DDR4_compute_overlap_bar_pct.png
#         ... (memory/sensors, DDR5)
# ============================================================================================

import math
from pathlib import Path
from typing import Optional, Dict, List

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from scipy.stats import spearmanr

# ---------- Paths (ROBUST) ----------
BASE_RES = ROOT / "Results"

# Use the PER-PLATFORM SHAP directory
OUT_DIR = BASE_RES / "Explainability_SHAP_BestPlatforms"
FIG_DIR = OUT_DIR / "comparison_plots_platform"
FIG_DIR.mkdir(parents=True, exist_ok=True)

DETAILS_CSV = BASE_RES / "BEST_in_DesignSpace_Post_per_platform_details.csv"
if not DETAILS_CSV.exists():
    raise FileNotFoundError(f"Missing per-platform details CSV: {DETAILS_CSV}")

SUBSPACES = ("compute", "memory", "sensors")
TOP_PCTS  = list(range(10, 101, 10))   # for overlap/jaccard sweep
TAKE_PCTS = list(range(10, 101, 10))   # which points to record

NORMALIZE_BY_PERCENTILE = True

# Where CP-MI ranks might be (first hit wins)
if "RANK_DIRS" not in globals():
    RANK_DIRS = [
        ROOT / "FeatureRankOUT",
        Path("/Volumes/Untitled") / "FeatureRankOUT",
        Path("/Volumes/Untitled") / "octaneX" / "FeatureRankOUT",
        Path.home() / "Desktop" / "octaneX" / "FeatureRankOUT",
    ]

def _read_csv_safe(p: Path) -> pd.DataFrame:
    try:
        return pd.read_csv(p)
    except Exception:
        return pd.DataFrame()

# ------------------------ CP-MI loader ------------------------
def _cpmi_rank_path(setup: str, win: int, kfold: int, sub: str) -> Optional[Path]:
    fname = f"{setup}_{win}_{kfold}_0_{sub}.csv"
    for d in RANK_DIRS:
        p = Path(d) / fname
        if p.exists():
            return p
    # fallback search (rare)
    for d in RANK_DIRS:
        d = Path(d)
        if not d.exists():
            continue
        hits = list(d.rglob(f"*{setup}*{sub}*CPMI*.csv")) + list(d.rglob(f"*{setup}*{sub}*CP-MI*.csv"))
        if hits:
            return hits[0]
    return None

def _load_cpmi(setup: str, win: int, kfold: int) -> Dict[str, pd.DataFrame]:
    """
    Returns dict[subspace] -> DataFrame(feature, cpmi_score, cpmi_rank), sorted by score desc.
    """
    out: Dict[str, pd.DataFrame] = {}
    for sub in SUBSPACES:
        rp = _cpmi_rank_path(setup, win, kfold, sub)
        if not rp:
            out[sub] = pd.DataFrame()
            continue
        df = _read_csv_safe(rp)
        if df.empty:
            out[sub] = df
            continue

        feat_col = None
        for c in df.columns:
            if c.lower() in ("feature", "features", "name", "signal", "column"):
                feat_col = c
                break
        if feat_col is None:
            nonnum = df.select_dtypes(exclude=[np.number]).columns
            feat_col = nonnum[0] if len(nonnum) else df.columns[0]

        score_col = None
        for c in df.columns:
            if c.lower() in ("cpmi", "cp-mi", "score", "mi", "mi_score", "rank_score"):
                score_col = c
                break
        if score_col is None:
            nums = df.select_dtypes(include=[np.number]).columns
            score_col = nums[0] if len(nums) else df.columns[-1]

        d = (
            df[[feat_col, score_col]]
            .rename(columns={feat_col: "feature", score_col: "cpmi_score"})
            .assign(feature=lambda x: x["feature"].astype(str).str.strip())
            .dropna(subset=["feature"])
            .drop_duplicates(subset=["feature"])
            .sort_values("cpmi_score", ascending=False)
            .reset_index(drop=True)
        )
        d["cpmi_rank"] = np.arange(1, len(d) + 1)
        out[sub] = d
    return out

# ------------------------ SHAP loader (per-platform best) ------------------------
def _shap_bestplat_full_path(setup: str, anomaly: str, win: int, kfold: int, pct: int, method: str) -> Path:
    return OUT_DIR / f"SHAP_BESTPLAT_full_{setup}_{anomaly}_WIN{win}_KF{kfold}_PCT{pct}_M{method}.csv"

def _load_shap_bestplat_full(setup: str, anomaly: str, win: int, kfold: int, pct: int, method: str) -> pd.DataFrame:
    p = _shap_bestplat_full_path(setup, anomaly, win, kfold, pct, method)
    df = _read_csv_safe(p)
    if df.empty:
        return df
    df.columns = [c.lower() for c in df.columns]
    # allow alt naming
    if "shap_mean_abs" not in df.columns and "importance" in df.columns:
        df = df.rename(columns={"importance": "shap_mean_abs"})
    # keep minimum set
    need = {"feature", "subspace", "shap_mean_abs"}
    if not need.issubset(df.columns):
        return pd.DataFrame()
    df["feature"] = df["feature"].astype(str).str.strip()
    df["subspace"] = df["subspace"].astype(str).str.lower()
    df["shap_mean_abs"] = pd.to_numeric(df["shap_mean_abs"], errors="coerce").fillna(0.0)
    return df[["feature", "subspace", "shap_mean_abs"]].copy()

# ------------------------ Aggregation helpers ------------------------
def _percentile_rank(series: pd.Series) -> pd.Series:
    n = len(series)
    if n <= 1:
        return pd.Series(np.zeros(n), index=series.index, dtype=float)
    r = series.rank(method="average", ascending=True)
    return (r - 1) / (n - 1)

def _aggregate_shap_platform(details_rows: pd.DataFrame, setup: str, subspace: str) -> pd.DataFrame:
    """
    details_rows: rows from BEST_in_DesignSpace_Post_per_platform_details.csv for this setup
    Returns: DataFrame(feature, shap_mean_abs_platform) for one subspace
    """
    parts: List[pd.DataFrame] = []
    for _, r in details_rows.iterrows():
        anomaly = str(r["anomaly"])
        win     = int(r["win"])
        kfold   = int(r["kfold"])
        pct     = int(r["best_pct_by_median"])
        method  = str(r["method"])

        df_shap = _load_shap_bestplat_full(setup, anomaly, win, kfold, pct, method)
        if df_shap.empty:
            continue

        sub_df = df_shap[df_shap["subspace"] == subspace][["feature", "shap_mean_abs"]].copy()
        sub_df = sub_df.rename(columns={"shap_mean_abs": f"shap_{anomaly}"})
        parts.append(sub_df)

    if not parts:
        return pd.DataFrame(columns=["feature", "shap_mean_abs_platform"])

    merged = None
    for d in parts:
        if merged is None:
            merged = d.copy()
        else:
            merged = merged.merge(d, on="feature", how="outer")

    shap_cols = [c for c in merged.columns if c.startswith("shap_")]
    merged[shap_cols] = merged[shap_cols].fillna(0.0)

    # equal-weight mean across anomalies
    merged["shap_mean_abs_platform"] = merged[shap_cols].mean(axis=1)

    out = merged[["feature", "shap_mean_abs_platform"]].copy()
    out["feature"] = out["feature"].astype(str)
    out["shap_mean_abs_platform"] = pd.to_numeric(out["shap_mean_abs_platform"], errors="coerce").fillna(0.0)
    return out

# ------------------------ Comparison ------------------------
def _compare_subspace(cpmi_df: pd.DataFrame, shap_df: pd.DataFrame) -> Optional[dict]:
    """
    cpmi_df: feature, cpmi_score, cpmi_rank
    shap_df: feature, shap_mean_abs_platform
    """
    if cpmi_df.empty or shap_df.empty:
        return None

    m = pd.merge(
        cpmi_df[["feature", "cpmi_score", "cpmi_rank"]],
        shap_df[["feature", "shap_mean_abs_platform"]],
        on="feature", how="inner"
    )
    if m.empty:
        return None

    m = m.copy()
    m["shap_rank"] = m["shap_mean_abs_platform"].rank(ascending=False, method="average").astype(float)

    if NORMALIZE_BY_PERCENTILE:
        m["cpmi_prank"] = _percentile_rank(-m["cpmi_rank"])
        m["shap_prank"] = _percentile_rank(-m["shap_rank"])
    else:
        m["cpmi_prank"] = np.nan
        m["shap_prank"] = np.nan

    rho_rank,  p_rank  = spearmanr(-m["cpmi_rank"], -m["shap_rank"])
    rho_prank, p_prank = (np.nan, np.nan)
    if NORMALIZE_BY_PERCENTILE:
        rho_prank, p_prank = spearmanr(m["cpmi_prank"], m["shap_prank"])
    rho_score, p_score = spearmanr(m["cpmi_score"], m["shap_mean_abs_platform"])

    rows = []
    n = len(m)
    for pct in TOP_PCTS:
        k = max(1, math.floor(pct * n / 100))
        top_c = set(m.sort_values("cpmi_rank").head(k)["feature"])
        top_s = set(m.sort_values("shap_rank").head(k)["feature"])
        inter = len(top_c & top_s)
        union = len(top_c | top_s) if (top_c or top_s) else 1
        rows.append({"k": f"top{pct}%", "overlap": inter, "jaccard": inter / union, "n_aligned": n})

    return {
        "aligned": m,
        "rho_rank": rho_rank, "p_rank": p_rank,
        "rho_prank": rho_prank, "p_prank": p_prank,
        "rho_score": rho_score, "p_score": p_score,
        "summary": pd.DataFrame(rows)
    }

# ------------------------ Plotting ------------------------
def _plot_platform(setup: str, subspace: str, comp: dict):
    aligned = comp["aligned"]
    case_tag = f"{setup}_{subspace}"

    plt.figure(figsize=(6, 5))
    plt.scatter(aligned["cpmi_score"], aligned["shap_mean_abs_platform"], s=12)
    plt.xlabel("CP-MI score")
    plt.ylabel("SHAP importance (mean |SHAP|) • platform-avg")
    plt.title(f"{setup} • {subspace} • CP-MI vs SHAP (ρ={comp['rho_score']:.2f})")
    plt.tight_layout()
    plt.savefig(FIG_DIR / f"{case_tag}_scatter_cpmi_vs_shap.png", dpi=220)
    plt.close()

    if "cpmi_prank" in aligned.columns and "shap_prank" in aligned.columns:
        plt.figure(figsize=(6, 5))
        plt.scatter(aligned["cpmi_prank"], aligned["shap_prank"], s=12)
        plt.xlabel("CP-MI percentile rank (higher = more important)")
        plt.ylabel("SHAP percentile rank (higher = more important)")
        plt.title(f"{setup} • {subspace} • Percentile Concordance (ρ={comp['rho_prank']:.2f})")
        plt.tight_layout()
        plt.savefig(FIG_DIR / f"{case_tag}_scatter_percentile_ranks.png", dpi=220)
        plt.close()

    s_pct = comp["summary"].copy()
    s_pct["pct"] = s_pct["k"].str.extract(r"top(\d+)%").astype(int)
    s_pct = s_pct.sort_values("pct")

    plt.figure(figsize=(6, 4))
    plt.plot(s_pct["pct"], s_pct["jaccard"], marker="o")
    plt.xlabel("Top-% of features")
    plt.ylabel("Jaccard (CP-MI vs SHAP)")
    plt.title(f"{setup} • {subspace} • Agreement vs Percentage")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(FIG_DIR / f"{case_tag}_jaccard_vs_pct.png", dpi=220)
    plt.close()

    plt.figure(figsize=(6, 4))
    plt.bar(s_pct["pct"].astype(str), s_pct["overlap"])
    plt.xlabel("Top-% of features")
    plt.ylabel("Overlap count")
    plt.title(f"{setup} • {subspace} • Overlap (CP-MI ∩ SHAP) vs %")
    plt.tight_layout()
    plt.savefig(FIG_DIR / f"{case_tag}_overlap_bar_pct.png", dpi=220)
    plt.close()

# ====================== Main ======================
details = pd.read_csv(DETAILS_CSV).copy()

# Normalize column naming
if "best_method" in details.columns and "method" not in details.columns:
    details = details.rename(columns={"best_method":"method"})
if "best_pct_by_median" not in details.columns and "pct" in details.columns:
    details = details.rename(columns={"pct":"best_pct_by_median"})

need_det = {"setup","anomaly","win","kfold","best_pct_by_median","method"}
missing = need_det - set(details.columns)
if missing:
    raise KeyError(f"{DETAILS_CSV} missing columns {sorted(missing)}. Have: {list(details.columns)}")

rows = []

for setup in ["DDR4","DDR5"]:
    dsetup = details[details["setup"].astype(str).str.upper() == setup].copy()
    if dsetup.empty:
        print(f"[WARN] No details rows for {setup}")
        continue

    # Use platform's WIN/K from the first row (they should be identical across anomalies for that setup)
    win_best = int(dsetup["win"].iloc[0])
    kf_best  = int(dsetup["kfold"].iloc[0])

    print(f"\n[PLATFORM] {setup} using WIN={win_best} K={kf_best}")

    cpmi = _load_cpmi(setup, win_best, kf_best)

    for sub in SUBSPACES:
        shap_plat = _aggregate_shap_platform(dsetup, setup=setup, subspace=sub)
        comp = _compare_subspace(cpmi.get(sub, pd.DataFrame()), shap_plat)

        if comp is None:
            rows.append({
                "setup": setup, "win": win_best, "kfold": kf_best,
                "subspace": sub, "k": "NA",
                "jaccard": np.nan, "overlap": np.nan,
                "rho_rank": np.nan, "rho_prank": np.nan, "rho_score": np.nan,
                "aligned_features": 0
            })
            continue

        _plot_platform(setup, sub, comp)

        s = comp["summary"].copy()
        s["pct"] = s["k"].str.extract(r"top(\d+)%").astype(int)
        s["k_eff"] = (np.floor(s["pct"] * s["n_aligned"] / 100)).astype(int).clip(lower=1)
        s = s.sort_values("pct").drop_duplicates(subset=["k_eff"], keep="first")
        take = s[s["pct"].isin(TAKE_PCTS)].copy()

        for _, rr in take.iterrows():
            rows.append({
                "setup": setup, "win": win_best, "kfold": kf_best,
                "subspace": sub, "k": rr["k"],
                "jaccard": rr["jaccard"], "overlap": rr["overlap"],
                "rho_rank": comp["rho_rank"], "rho_prank": comp["rho_prank"], "rho_score": comp["rho_score"],
                "aligned_features": int(comp["aligned"].shape[0])
            })

out_csv = OUT_DIR / "SHAP_vs_CPMI_summary_PLATFORM.csv"
pd.DataFrame(rows).to_csv(out_csv, index=False)
print(f"\n[OK] Summary → {out_csv}")
print(f"[OK] Plots   → {FIG_DIR}")